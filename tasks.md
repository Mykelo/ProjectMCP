# MCP BigQuery Server - Task List

**Status Legend**: ğŸ”´ Not Started | ğŸŸ¡ In Progress | ğŸŸ¢ Complete | â¸ï¸ Blocked

---

## Phase 1: Project Setup & Foundation ğŸ”´

### 1.1 Initialize Project Structure
- [ ] ğŸ”´ Create project root directory structure
- [ ] ğŸ”´ Initialize git repository with .gitignore
- [ ] ğŸ”´ Create README.md with project overview
- [ ] ğŸ”´ Set up directory structure:
  ```
  ProjectMCP/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ mcp_bigquery/
  â”‚   â”‚   â”œâ”€â”€ __init__.py
  â”‚   â”‚   â”œâ”€â”€ server.py
  â”‚   â”‚   â”œâ”€â”€ auth.py
  â”‚   â”‚   â”œâ”€â”€ bigquery_client.py
  â”‚   â”‚   â””â”€â”€ config.py
  â”œâ”€â”€ tests/
  â”œâ”€â”€ docs/
  â”œâ”€â”€ .env.example
  â”œâ”€â”€ pyproject.toml
  â”œâ”€â”€ Dockerfile
  â”œâ”€â”€ docker-compose.yml
  â””â”€â”€ README.md
  ```

**Estimated Time**: 30 minutes

---

### 1.2 Configure uv Package Manager
- [ ] ğŸ”´ Install uv on development machine
- [ ] ğŸ”´ Create pyproject.toml with project metadata
- [ ] ğŸ”´ Define dependencies:
  - fastmcp
  - google-cloud-bigquery>=3.38.0
  - python-dotenv
  - pydantic
  - pydantic-settings
- [ ] ğŸ”´ Create uv.lock file
- [ ] ğŸ”´ Test dependency installation

**Estimated Time**: 45 minutes

---

## Phase 2: Core MCP Server Implementation ğŸ”´

### 2.1 Configuration Management
- [ ] ğŸ”´ Create config.py with Pydantic Settings
- [ ] ğŸ”´ Define environment variables:
  - BEARER_TOKEN
  - GOOGLE_APPLICATION_CREDENTIALS
  - GCP_PROJECT_ID
  - LOG_LEVEL
- [ ] ğŸ”´ Create .env.example template
- [ ] ğŸ”´ Add validation for required settings

**Estimated Time**: 1 hour

---

### 2.2 Bearer Token Authentication
- [ ] ğŸ”´ Create auth.py module
- [ ] ğŸ”´ Implement bearer token validation function
- [ ] ğŸ”´ Create authentication decorator for MCP tools
- [ ] ğŸ”´ Add token extraction from MCP context/headers
- [ ] ğŸ”´ Implement error responses for invalid tokens (MCP error format)
- [ ] ğŸ”´ Add logging for authentication attempts
- [ ] ğŸ”´ Write unit tests for authentication

**Estimated Time**: 2 hours

---

### 2.3 BigQuery Client Wrapper
- [ ] ğŸ”´ Create bigquery_client.py module
- [ ] ğŸ”´ Initialize BigQuery client with credentials
- [ ] ğŸ”´ Implement query execution function (QueryJob.result() â†’ RowIterator)
- [ ] ğŸ”´ Implement list datasets function (Client.list_datasets)
- [ ] ğŸ”´ Implement get dataset info function (Client.get_dataset)
- [ ] ğŸ”´ Implement list tables function (Client.list_tables)
- [ ] ğŸ”´ Implement get table info function (Client.get_table)
- [ ] ğŸ”´ Add error handling and logging
- [ ] ğŸ”´ Write unit tests with mocked BigQuery client

**Estimated Time**: 3 hours

---

### 2.4 FastMCP Server Implementation
- [ ] ğŸ”´ Create server.py with FastMCP app initialization
- [ ] ğŸ”´ Define MCP tools with @mcp.tool decorator:
  - `list_datasets`: List BigQuery datasets (with pagination)
  - `get_dataset_info`: Get dataset metadata
  - `list_tables`: List tables in a dataset (with pagination)
  - `get_table_info`: Get table metadata and schema
  - `execute_query`: Execute SQL query and return results (with pagination)
- [ ] ğŸ”´ Add Pydantic Field constraints for validation (FQID patterns, ranges)
- [ ] ğŸ”´ Integrate bearer token authentication (decorator or middleware)
- [ ] ğŸ”´ Integrate BigQuery client wrapper
- [ ] ğŸ”´ Add comprehensive error handling (BigQuery exceptions â†’ MCP errors)
- [ ] ğŸ”´ Add structured logging
- [ ] ğŸ”´ Implement pagination support (page_size, page_token, next_page_token)

**Estimated Time**: 4 hours

---

## Phase 3: Containerization ğŸ”´

### 3.1 Dockerfile Creation
- [ ] ğŸ”´ Create multi-stage Dockerfile
- [ ] ğŸ”´ Stage 1: Build stage with uv
- [ ] ğŸ”´ Stage 2: Runtime stage (minimal image)
- [ ] ğŸ”´ Copy application code
- [ ] ğŸ”´ Set up proper user permissions (non-root)
- [ ] ğŸ”´ Define ENTRYPOINT and CMD (fastmcp run or python -m mcp_bigquery)
- [ ] ğŸ”´ Expose ports if using SSE transport (optional)
- [ ] ğŸ”´ Test Docker build locally

**Estimated Time**: 2 hours

---

### 3.2 Docker Compose Setup
- [ ] ğŸ”´ Create docker-compose.yml
- [ ] ğŸ”´ Define service configuration
- [ ] ğŸ”´ Set up volume mounts for credentials
- [ ] ğŸ”´ Configure environment variables
- [ ] ğŸ”´ Add health check configuration
- [ ] ğŸ”´ Test with docker-compose up

**Estimated Time**: 1.5 hours

---

### 3.3 Container Optimization
- [ ] ğŸ”´ Optimize image size
- [ ] ğŸ”´ Add .dockerignore file
- [ ] ğŸ”´ Implement proper logging for containers
- [ ] ğŸ”´ Add container health checks
- [ ] ğŸ”´ Document port mappings and volumes

**Estimated Time**: 1 hour

---

## Phase 4: Testing & Validation ğŸ”´

### 4.1 Unit Tests
- [ ] ğŸ”´ Set up pytest configuration
- [ ] ğŸ”´ Write tests for auth module
- [ ] ğŸ”´ Write tests for config module
- [ ] ğŸ”´ Write tests for BigQuery client wrapper
- [ ] ğŸ”´ Mock external BigQuery API calls
- [ ] ğŸ”´ Achieve >80% code coverage

**Estimated Time**: 3 hours

---

### 4.2 Integration Tests
- [ ] ğŸ”´ Test full MCP tool execution flow
- [ ] ğŸ”´ Test authentication integration
- [ ] ğŸ”´ Test BigQuery query execution (with test dataset)
- [ ] ğŸ”´ Test error scenarios
- [ ] ğŸ”´ Validate MCP protocol compliance

**Estimated Time**: 2 hours

---

### 4.3 Docker Testing
- [ ] ğŸ”´ Test container builds successfully
- [ ] ğŸ”´ Test container starts and runs
- [ ] ğŸ”´ Test authentication in container
- [ ] ğŸ”´ Test BigQuery connectivity from container
- [ ] ğŸ”´ Test environment variable injection

**Estimated Time**: 1.5 hours

---

## Phase 5: Documentation ğŸ”´

### 5.1 User Documentation
- [ ] ğŸ”´ Write comprehensive README.md
- [ ] ğŸ”´ Document installation steps
- [ ] ğŸ”´ Document configuration options
- [ ] ğŸ”´ Create quickstart guide
- [ ] ğŸ”´ Document available MCP tools (reference docs/TOOLS.md)
- [ ] ğŸ”´ Add MCP client setup instructions (Claude Desktop, etc.)
- [ ] ğŸ”´ Add troubleshooting section

**Estimated Time**: 2 hours

---

### 5.2 Developer Documentation
- [ ] ğŸ”´ Document code architecture
- [ ] ğŸ”´ Add inline code comments
- [ ] ğŸ”´ Create CONTRIBUTING.md
- [ ] ğŸ”´ Document testing procedures
- [ ] ğŸ”´ Add examples of common use cases

**Estimated Time**: 1.5 hours

---

### 5.3 Deployment Documentation
- [ ] ğŸ”´ Document Docker deployment
- [ ] ğŸ”´ Document environment setup
- [ ] ğŸ”´ Document BigQuery service account setup
- [ ] ğŸ”´ Create deployment checklist
- [ ] ğŸ”´ Add security best practices

**Estimated Time**: 1 hour

---

## Phase 6: Security & Best Practices ğŸ”´

### 6.1 Security Hardening
- [ ] ğŸ”´ Implement secrets management best practices
- [ ] ğŸ”´ Add input validation and sanitization
- [ ] ğŸ”´ Implement rate limiting (if needed)
- [ ] ğŸ”´ Security audit of dependencies
- [ ] ğŸ”´ Add security headers
- [ ] ğŸ”´ Document security considerations

**Estimated Time**: 2 hours

---

### 6.2 Code Quality
- [ ] ğŸ”´ Add pre-commit hooks
- [ ] ğŸ”´ Configure code formatting (black/ruff)
- [ ] ğŸ”´ Configure linting (ruff/pylint)
- [ ] ğŸ”´ Add type checking with mypy
- [ ] ğŸ”´ Run security scanner (bandit)

**Estimated Time**: 1.5 hours

---

## Phase 7: Final Polish & Release ğŸ”´

### 7.1 Final Testing
- [ ] ğŸ”´ End-to-end testing
- [ ] ğŸ”´ Performance testing
- [ ] ğŸ”´ Load testing (if applicable)
- [ ] ğŸ”´ Security testing
- [ ] ğŸ”´ Documentation review

**Estimated Time**: 2 hours

---

### 7.2 Release Preparation
- [ ] ğŸ”´ Version tagging
- [ ] ğŸ”´ Create CHANGELOG.md
- [ ] ğŸ”´ Prepare release notes
- [ ] ğŸ”´ Build and tag Docker image
- [ ] ğŸ”´ Final documentation review

**Estimated Time**: 1 hour

---

## Summary

**Total Estimated Time**: ~30 hours
**Recommended Timeline**: 5-7 days (with 4-6 hours per day)

### Phases Breakdown:
1. **Phase 1** (Setup): 1.25 hours
2. **Phase 2** (Core Implementation): 10 hours
3. **Phase 3** (Containerization): 4.5 hours
4. **Phase 4** (Testing): 6.5 hours
5. **Phase 5** (Documentation): 4.5 hours
6. **Phase 6** (Security): 3.5 hours
7. **Phase 7** (Release): 3 hours

### Critical Path:
1. Project Setup â†’ 2. Core Implementation â†’ 3. Containerization â†’ 4. Testing

### Dependencies:
- BigQuery service account JSON credentials
- Docker installed on development machine
- GCP project with BigQuery API enabled
- uv package manager installed
- MCP client (e.g., Claude Desktop) for testing

### Reference Documentation:
- Tool specifications: `docs/TOOLS.md`
- FastMCP tools guide: https://gofastmcp.com/servers/tools
- BigQuery Python client: https://cloud.google.com/python/docs/reference/bigquery/latest/summary_method

---

## Notes & Considerations

### MCP Tools Implementation
The server will expose 5 FastMCP tools:
1. **list_datasets** - List BigQuery datasets with pagination
2. **get_dataset_info** - Get dataset metadata (location, description, labels, access)
3. **list_tables** - List tables in a dataset with pagination
4. **get_table_info** - Get table metadata (schema, rows, bytes, partitioning, clustering)
5. **execute_query** - Execute SQL queries with pagination and statistics

All tools use:
- Type annotations for automatic schema generation
- Pydantic Field constraints for validation (patterns, ranges)
- Bearer token authentication (decorator/middleware)
- Consistent error handling (BigQuery exceptions â†’ MCP errors)

### BigQuery API Quotas
- Be aware of BigQuery API quotas and limits
- Consider implementing query result caching
- Add query timeout configurations

### MCP Protocol Compliance
- Follow FastMCP best practices (use @mcp.tool decorator)
- Ensure proper error message formatting (MCP error results)
- Use type annotations and Pydantic Field for schema generation
- Implement standard MCP response structures (dict returns)
- Support pagination with page_size, page_token, next_page_token

### Bearer Token Security
- Generate secure random tokens (32+ characters)
- Consider token rotation strategy
- Document token generation process

### Future Enhancements (Post-MVP)
- [ ] Add query result streaming (to_arrow_iterable, to_dataframe_iterable)
- [ ] Implement query result caching
- [ ] Add support for parameterized queries (ScalarQueryParameter, arrays, structs)
- [ ] Add BigQuery job management tools (list jobs, cancel job, get job details)
- [ ] Use BigQuery Storage API for faster reads (bqstorage_client)
- [ ] Add MCP resources (in addition to tools) for browsing datasets/tables
- [ ] Multi-tenant support with multiple bearer tokens
- [ ] Add dataset/table creation and modification tools
